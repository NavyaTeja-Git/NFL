{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOQsrtJSk3gJ",
        "outputId": "47431d33-e4fb-44b7-b2a2-0dda99948d2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install beautifulsoup4 requests pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCuHcUjbklnO",
        "outputId": "360060e5-c2f1-4afc-f8c6-73d69f5dc094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to 2017_NFL_Draft_AV_Averages.csv\n",
            "Name: Myles Garrett, Pick: 1, Average AV Values: [4.0, 14.0, 5.0, 15.0, 17.0], URL: https://www.pro-football-reference.com/players/G/GarrMy00.htm\n",
            "Name: Mitchell Trubisky, Pick: 2, Average AV Values: [8.0, 13.0, 8.0, 7.0, 0.0], URL: https://www.pro-football-reference.com/players/T/TrubMi00.htm\n",
            "Name: Solomon Thomas, Pick: 3, Average AV Values: [6.0, 6.0, 3.0, 1.0, 1.0], URL: https://www.pro-football-reference.com/players/T/ThomSo00.htm\n",
            "Name: Leonard Fournette, Pick: 4, Average AV Values: [8.0, 3.0, 10.0, 5.0, 9.0], URL: https://www.pro-football-reference.com/players/F/FourLe00.htm\n",
            "Name: Corey Davis, Pick: 5, Average AV Values: [3.0, 7.0, 5.0, 11.0, 4.0], URL: https://www.pro-football-reference.com/players/D/DaviCo03.htm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-9e8dd1a545d2>:93: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'NaN' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.fillna('NaN', inplace=True)\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "# URL for the 2017 NFL draft\n",
        "draft_url = 'https://www.pro-football-reference.com/years/2017/draft.htm'\n",
        "\n",
        "# Get the draft page\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36'\n",
        "}\n",
        "draft_response = requests.get(draft_url, headers=headers)\n",
        "\n",
        "# Check the request\n",
        "if draft_response.status_code != 200:\n",
        "    print(f\"Failed to retrieve page. Status code: {draft_response.status_code}\")\n",
        "else:\n",
        "    # Parse the page content using BeautifulSoup\n",
        "    soup = BeautifulSoup(draft_response.content, 'html.parser')\n",
        "\n",
        "    # Find the table containing drafted players\n",
        "    draft_table = soup.find('table', {'id': 'drafts'})\n",
        "\n",
        "    # Check if the table was found\n",
        "    if draft_table is None:\n",
        "        print(\"Draft table not found on the page. Please check the page structure.\")\n",
        "    else:\n",
        "        # Extract player URLs\n",
        "        player_data = []\n",
        "        for row in draft_table.find('tbody').find_all('tr'):\n",
        "            # Skip header rows\n",
        "            if row.get('class') and 'thead' in row.get('class'):\n",
        "                continue\n",
        "\n",
        "            player_link = row.find('td', {'data-stat': 'player'})\n",
        "            if player_link and player_link.a:\n",
        "                player_name = player_link.a.text\n",
        "                player_url = 'https://www.pro-football-reference.com' + player_link.a['href']\n",
        "                year_drafted = 2017\n",
        "                pick = row.find('td', {'data-stat': 'draft_pick'}).text\n",
        "                player_data.append({'name': player_name, 'url': player_url, 'year_drafted': year_drafted, 'pick': pick})\n",
        "\n",
        "        # Function to extract AV values from all tables on a player's page\n",
        "        def extract_av_values(player_url, year_drafted):\n",
        "            response = requests.get(player_url, headers=headers)\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "            # Initialize AV values with NaN for each year in the 5-year window\n",
        "            av_values_by_year = {year: [] for year in range(year_drafted, year_drafted + 5)}\n",
        "\n",
        "            # Find all tables in the player's page\n",
        "            tables = soup.find_all('table')\n",
        "            for table in tables:\n",
        "                # Check if table contains AV data by searching for 'av' in data-stat attributes\n",
        "                for row in table.find('tbody').find_all('tr'):\n",
        "                    year_cell = row.find('th', {'data-stat': 'year_id'})\n",
        "                    if year_cell:\n",
        "                        year = year_cell.text.strip()\n",
        "                        clean_year = ''.join(filter(str.isdigit, year))  # Remove non-numeric characters from year\n",
        "                        try:\n",
        "                            clean_year = int(clean_year)\n",
        "                        except ValueError:\n",
        "                            continue\n",
        "\n",
        "                        # Check if the year is within the 5-year window since being drafted\n",
        "                        if year_drafted <= clean_year < year_drafted + 5:\n",
        "                            av_cell = row.find('td', {'data-stat': 'av'})\n",
        "                            if av_cell and av_cell.text.strip().isdigit():\n",
        "                                av_value = int(av_cell.text.strip())\n",
        "                                av_values_by_year[clean_year].append(av_value)\n",
        "\n",
        "            # Calculate the average AV for each year (use np.nanmean to handle empty lists)\n",
        "            avg_av_values = [np.nanmean(av_values_by_year[year]) if av_values_by_year[year] else np.nan\n",
        "                             for year in range(year_drafted, year_drafted + 5)]\n",
        "\n",
        "            return avg_av_values\n",
        "\n",
        "        # Loop through each player and get average AV values with a delay to avoid throttling\n",
        "        for player in player_data:\n",
        "            time.sleep(2)  # Add a 2-second delay between requests\n",
        "            avg_av_values = extract_av_values(player['url'], player['year_drafted'])\n",
        "            player['avg_av_values'] = avg_av_values\n",
        "\n",
        "        # Save the data to a DataFrame\n",
        "        df = pd.DataFrame(player_data)\n",
        "        av_columns = ['year_1_avg_av', 'year_2_avg_av', 'year_3_avg_av', 'year_4_avg_av', 'year_5_avg_av']\n",
        "        df[av_columns] = pd.DataFrame(df['avg_av_values'].tolist(), index=df.index)\n",
        "        df = df.drop(columns=['avg_av_values'])  # Drop avg_av_values column after splitting into separate years\n",
        "\n",
        "        # Handle NaN explicitly for better CSV output\n",
        "        df.fillna('NaN', inplace=True)\n",
        "\n",
        "        # Save the DataFrame to a CSV file\n",
        "        df.to_csv('2017_NFL_Draft_AV_Averages.csv', index=False)\n",
        "        print(\"Data saved to 2017_NFL_Draft_AV_Averages.csv\")\n",
        "\n",
        "        # Display results for validation\n",
        "        for player in player_data[:5]:  # Displaying only the first 5 players to keep output manageable\n",
        "            print(f\"Name: {player['name']}, Pick: {player['pick']}, Average AV Values: {player['avg_av_values']}, URL: {player['url']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the 2017 NFL Draft AV Averages file\n",
        "df_2017 = pd.read_csv('2017_NFL_Draft_AV_Averages.csv')\n",
        "\n",
        "# Calculate cumulative AV values\n",
        "df_2017['CUMYr1'] = df_2017['year_1_avg_av']  # Cumulative for the first year\n",
        "df_2017['CUMYr2'] = df_2017[['year_1_avg_av', 'year_2_avg_av']].sum(axis=1)  # Sum of year_1 and year_2\n",
        "df_2017['CUMYr3'] = df_2017[['year_1_avg_av', 'year_2_avg_av', 'year_3_avg_av']].sum(axis=1)  # Sum of year_1 to year_3\n",
        "df_2017['CUMYr4'] = df_2017[['year_1_avg_av', 'year_2_avg_av', 'year_3_avg_av', 'year_4_avg_av']].sum(axis=1)  # Sum of year_1 to year_4\n",
        "df_2017['CUMYr5'] = df_2017[['year_1_avg_av', 'year_2_avg_av', 'year_3_avg_av', 'year_4_avg_av', 'year_5_avg_av']].sum(axis=1)  # Sum of year_1 to year_5\n",
        "\n",
        "# Save the result to a new CSV file\n",
        "df_2017.to_csv('2017_NFL_Draft_Cumulative_AV.csv', index=False)\n",
        "print(\"Cumulative AV values calculated and saved for 2017.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWBIwmY4yzFi",
        "outputId": "2e5720b4-0d4f-4eea-9790-2e4ae003a274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cumulative AV values calculated and saved for 2017.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}